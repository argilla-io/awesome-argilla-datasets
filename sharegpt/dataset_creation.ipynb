{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiCZcohFc_mu"
      },
      "source": [
        "# Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-cpp-python textdescriptives argilla transformers datasets langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
            "Requirement already satisfied: ctransformers in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (0.2.27)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from ctransformers) (0.17.3)\n",
            "Requirement already satisfied: fsspec in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
            "Requirement already satisfied: filelock in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
            "Requirement already satisfied: requests in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (4.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (3.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!CT_METAL=1 pip install -q ctransformers --no-binary ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from ctransformers import AutoModelForCausalLM\n",
        "\n",
        "# # Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
        "# llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\", model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_type=\"mistral\")\n",
        "\n",
        "# print(llm(\"AI is going to\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import textdescriptives as td\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "import argilla as rg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpkYEwr5dD6w"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "End-to-end workflow to create a dataset in Argilla with text measurements as metadata.\n",
        "This aids in quickly identifying and improving potential dataset issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset creation\n",
        "\n",
        "At first, we need to create a dataset in Argilla. This can either be done by loading a previous created dataset or by creating a new one. In order to avoid duplication, we will check if the dataset already exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RemoteFeedbackDataset(\n",
              "   id=8eb16dbb-1019-40d9-aa8d-b6b25164a268\n",
              "   name=sharegpt\n",
              "   workspace=Workspace(id=e41766d9-89eb-4497-afce-1d96c7ff5f51, name=argilla, inserted_at=2023-10-28 11:26:52.619081, updated_at=2023-10-28 11:26:52.619081)\n",
              "   url=http://localhost:6900/dataset/8eb16dbb-1019-40d9-aa8d-b6b25164a268/annotation-mode\n",
              "   fields=[RemoteTextField(id=UUID('9614aac2-c840-4715-9095-d751cb0ca79e'), client=None, name='prompt', title='Prompt', required=True, type='text', use_markdown=True), RemoteTextField(id=UUID('680f6051-5c48-46fe-bd14-8253c23660d6'), client=None, name='context', title='Context', required=False, type='text', use_markdown=True)]\n",
              "   questions=[RemoteTextQuestion(id=UUID('0214cd83-42f6-4a42-825b-2c986adbd4e8'), client=None, name='response', title='Response', description=None, required=True, type='text', use_markdown=True), RemoteRatingQuestion(id=UUID('9ede196e-6e3f-43f0-8d81-59fe1de05399'), client=None, name='prompt-quality', title='Prompt Quality', description=None, required=True, type='rating', values=[1, 2, 3, 4, 5, 6, 7]), RemoteLabelQuestion(id=UUID('774a76de-4557-4a15-b8cc-679369fd5c8e'), client=None, name='prompt-intent', title='Prompt Intent', description=None, required=True, type='label_selection', labels=['generation', 'rewrite', 'extract', 'closed-qa', 'open-qa', 'classification', 'summarization', 'brainstorming', 'chat', 'code', 'other'], visible_labels=None), RemoteMultiLabelQuestion(id=UUID('e8d55f26-9e38-4acd-8ea6-bc26ff355414'), client=None, name='prompt-toxicity', title='Prompt Toxicity', description=None, required=False, type='multi_label_selection', labels=['illegal', 'harmfull', 'unqualified advice'], visible_labels=None)]\n",
              "   guidelines=This is a supervised fine-tuning dataset that contains instructions. Please write the response to the instruction in the response field. Take the context into account when writing the response.)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    ds_local = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "    ds_local.questions.extend([\n",
        "        rg.RatingQuestion(\n",
        "            name=\"prompt-quality\", \n",
        "            title=\"Prompt Quality\",\n",
        "            values=list(range(1, 8)), \n",
        "            description=\"How would you rate the quality of the prompt?\",\n",
        "        ),\n",
        "        rg.LabelQuestion(\n",
        "            name=\"prompt-intent\", \n",
        "            title=\"Prompt Intent\",\n",
        "            labels=[\"generation\", \"rewrite\", \"extract\", \"closed-qa\", \"open-qa\", \"classification\", \"summarization\", \"brainstorming\", \"chat\", \"code\", \"other\"], \n",
        "            description=\"What is the intent of the prompt?\"\n",
        "        ),\n",
        "        rg.MultiLabelQuestion(\n",
        "            name=\"prompt-toxicity\", \n",
        "            title=\"Prompt Toxicity\",\n",
        "            labels=[\"illegal\", \"harmfull\", \"unqualified advice\"], \n",
        "            description=\"What are the toxicities in the prompt (if any)?\",\n",
        "            required=False\n",
        "        )\n",
        "    ])\n",
        "    ds_remote = ds_local.push_to_argilla(\"sharegpt\")\n",
        "except Exception as e:\n",
        "    ds_remote = rg.FeedbackDataset.from_argilla(\"sharegpt\")\n",
        "ds_remote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Configure the metadata-properties\n",
        "\n",
        "Next we will be using `text-descriptives` to configure the metadata-properties. This will be used to add and updat relevant metadata-properties to the dataset. Because `text-descriptives` doesn't provide any programmatic interface with the metrics-groups and their sub-metrics, we will run the computation on the an example text and use the results to configure the metadata-properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Both a spacy model and a language were provided. Will use the spacy\n",
            "model and ignore language.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['token_length_mean', 'token_length_median', 'token_length_std',\n",
              "       'sentence_length_mean', 'sentence_length_median', 'sentence_length_std',\n",
              "       'syllables_per_token_mean', 'syllables_per_token_median',\n",
              "       'syllables_per_token_std', 'n_tokens', 'n_unique_tokens',\n",
              "       'proportion_unique_tokens', 'n_characters', 'n_sentences'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric_group = [\"descriptive_stats\"]\n",
        "relevant_subgroups = []\n",
        "df_metrics = td.extract_metrics(\n",
        "    text=[\"this is an example prompt\"], \n",
        "    lang=\"en\", \n",
        "    metrics=metric_group,\n",
        "    spacy_model=\"en_core_web_sm\"\n",
        ").drop(columns=[\"text\"] + relevant_subgroups if relevant_subgroups else [\"text\"])\n",
        "df_metrics.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will be working on converting the `text-descriptives` output to a format that can be used to configure the metadata-properties for our supported types: `TermsMetadataProperty`, `IntegerMetadataProperty` and `FloatMetadataProperty`. Note that we are also applying some subjective formatting choices to ensure that the metadata-properties are easy to read and understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_column_name(col_name):\n",
        "    \"\"\"Clean a column name to fit a specific regex pattern.\"\"\"\n",
        "    col_name = col_name.lower()  # Convert to lowercase\n",
        "    col_name = re.sub(r'[^a-z0-9_]', '_', col_name)  # Replace non-alphanumeric characters with underscores\n",
        "    return col_name\n",
        "\n",
        "def create_metadata_properties(df, prefix):\n",
        "    \"\"\"Generate metadata properties based on dataframe columns and data types.\"\"\"\n",
        "    properties = []\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        name = f\"{prefix}_{clean_column_name(col)}\"\n",
        "        title = name.replace('_', ' ').title()\n",
        "\n",
        "        if dtype == 'object':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'int64':\n",
        "            prop = rg.IntegerMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'float64':\n",
        "            prop = rg.FloatMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'bool':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        else:\n",
        "            print(f\"Unhandled data type for column {col}: {dtype}\")\n",
        "            continue\n",
        "        properties.append(prop)\n",
        "    return properties\n",
        "\n",
        "metadata_properties = create_metadata_properties(df_metrics, 'prompt')\n",
        "for metadata_property in metadata_properties:\n",
        "    try:\n",
        "        ds_remote.metadata_property_by_name(metadata_property.name)\n",
        "    except KeyError:\n",
        "        ds_remote.add_metadata_property(metadata_property)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"totally-not-an-llm/sharegpt-hyperfiltered-3k\", split=\"train\")\n",
        "dataset = dataset.filter(lambda x: x[\"conversations\"][0][\"from\"] == \"human\")\n",
        "dataset = dataset.map(lambda x: {\"prompt\": x[\"conversations\"][0][\"value\"], \"response\": x[\"conversations\"][1][\"value\"]})\n",
        "\n",
        "# Extract metrics\n",
        "df_prompt = td.extract_metrics(text=dataset[\"prompt\"], lang=\"en\", spacy_model=\"en\").drop(columns=['text'])\n",
        "df_response = td.extract_metrics(text=dataset[\"response\"], lang=\"en\", spacy_model=\"en\").drop(columns=['text'])\n",
        "\n",
        "# Identify integer and boolean columns for prompts and responses\n",
        "int_cols_prompts = df_prompt.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_prompts = df_prompt.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "int_cols_responses = df_response.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_responses = df_response.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "# Combine column lists for prompts and responses\n",
        "int_cols = list(set(int_cols_prompts + int_cols_responses))\n",
        "bool_cols = list(set(bool_cols_prompts + bool_cols_responses))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zt9XZrLtc2Km"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Downloading readme: 100%|██████████| 665/665 [00:00<00:00, 1.24MB/s]\n",
            "Downloading data: 100%|██████████| 6.27M/6.27M [00:01<00:00, 5.25MB/s]\n",
            "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
            "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 460.00it/s]\n",
            "Generating train split: 3243 examples [00:00, 68097.46 examples/s]\n",
            "Filter: 100%|██████████| 3243/3243 [00:00<00:00, 41241.81 examples/s]\n",
            "Map: 100%|██████████| 3241/3241 [00:00<00:00, 11316.58 examples/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ No spacy model provided. Inferring spacy model for en.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
            "Collecting en-core-web-lg==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from en-core-web-lg==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.3.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.2.1)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (58.1.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: jinja2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (23.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages/textdescriptives/components/coherence.py:44: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
            "  similarities.append(sent.similarity(sents[i + order]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ No spacy model provided. Inferring spacy model for en.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
            "Collecting en-core-web-lg==3.7.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0-py3-none-any.whl (587.7 MB)\n",
            "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from en-core-web-lg==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: setuptools in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (58.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (23.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: jinja2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.3.3)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.2.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (3.3.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-lg==3.7.0) (2.1.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages/textdescriptives/components/coherence.py:44: UserWarning: [W008] Evaluating Span.similarity based on empty vectors.\n",
            "  similarities.append(sent.similarity(sents[i + order]))\n",
            "/Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages/argilla/client/client.py:154: UserWarning: Default user was detected and no workspace configuration was provided, so the default 'argilla' workspace will be used. If you want to setup another workspace, use the `rg.set_workspace` function or provide a different one on `rg.init`\n",
            "  warnings.warn(\n",
            "Pushing records to Argilla...: 100%|██████████| 102/102 [00:20<00:00,  5.04it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RemoteFeedbackDataset(\n",
              "   id=853fc94e-6e92-4361-927c-3100024394ad\n",
              "   name=share-gpt-descriptives\n",
              "   workspace=Workspace(id=e41766d9-89eb-4497-afce-1d96c7ff5f51, name=argilla, inserted_at=2023-10-28 11:26:52.619081, updated_at=2023-10-28 11:26:52.619081)\n",
              "   url=http://localhost:6900/dataset/853fc94e-6e92-4361-927c-3100024394ad/annotation-mode\n",
              "   fields=[RemoteTextField(id=UUID('0c4d73f7-83f7-4501-86ce-6a06ceb075e3'), client=None, name='prompt', title='Prompt', required=True, type='text', use_markdown=True), RemoteTextField(id=UUID('07c28c08-51d6-40d6-9bb1-ebdd33b7348c'), client=None, name='context', title='Context', required=False, type='text', use_markdown=True)]\n",
              "   questions=[RemoteTextQuestion(id=UUID('cfe300a8-3ff8-4284-b14f-0e3175b055d2'), client=None, name='response', title='Response', description=None, required=True, type='text', use_markdown=True)]\n",
              "   guidelines=This is a supervised fine-tuning dataset that contains instructions. Please write the response to the instruction in the response field. Take the context into account when writing the response.)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def cast_to_python_types(df):\n",
        "    \"\"\"\n",
        "    Convert integer and boolean columns to Python native types.\n",
        "    \"\"\"\n",
        "    int_cols = df.select_dtypes(include=['int64']).columns\n",
        "    bool_cols = df.select_dtypes(include=['boolean']).columns\n",
        "\n",
        "    # Explicitly cast integers using Python's native int type\n",
        "    for col in int_cols:\n",
        "        df[col] = df[col].apply(int)\n",
        "\n",
        "    # Convert booleans to strings using Python's native str type\n",
        "    for col in bool_cols:\n",
        "        df[col] = df[col].apply(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def detect_language(text):\n",
        "    \"\"\"\n",
        "    Detect the language of a given text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "    - str: Detected language (ISO 639-1 code).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"unknown\"  # In case the language detection fails\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Metadata Preparation ---\n",
        "metadata_prompt = create_metadata_properties(df_prompt, 'prompt')\n",
        "metadata_response = create_metadata_properties(df_response, 'response')\n",
        "\n",
        "all_metadata = metadata_prompt + metadata_response\n",
        "\n",
        "ds = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "for m in all_metadata:\n",
        "    ds.add_metadata_property(m)\n",
        "\n",
        "# --- Record Preparation ---\n",
        "records = []\n",
        "\n",
        "# Prepare feedback records with metadata and suggestions\n",
        "\n",
        "# Identify columns with values other than zeros or NaN for both prompt and response\n",
        "cols_with_values_other_than_zeros_or_nan_prompt = df_prompt.columns[~(df_prompt.fillna(0) == 0).all()].tolist()\n",
        "cols_with_values_other_than_zeros_or_nan_response = df_response.columns[~(df_response.fillna(0) == 0).all()].tolist()\n",
        "\n",
        "\n",
        "records = []\n",
        "\n",
        "cols_with_values_other_than_zeros_or_nan_prompt = df_prompt.columns[~(df_prompt.fillna(0) == 0).all() & ~df_prompt.isnull().any()].tolist()\n",
        "cols_with_values_other_than_zeros_or_nan_response = df_response.columns[~(df_response.fillna(0) == 0).all() & ~df_response.isnull().any()].tolist()\n",
        "\n",
        "ds = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "for m in all_metadata:\n",
        "    ds.add_metadata_property(m)\n",
        "\n",
        "for i, record in enumerate(dataset):\n",
        "    # Prepare metadata for prompts\n",
        "    metadata_prompts = {f\"prompt_{col}\": value for col, value in df_prompt[cols_with_values_other_than_zeros_or_nan_prompt].iloc[i].items()}\n",
        "    # Prepare metadata for responses\n",
        "    metadata_response = {f\"response_{col}\": value for col, value in df_response[cols_with_values_other_than_zeros_or_nan_response].iloc[i].items()}\n",
        "    if \"prompt_smog\" in metadata_prompts.keys():\n",
        "      print(metadata_prompts)\n",
        "\n",
        "    # Explicitly cast integers using Python's native int type\n",
        "    for col in int_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = int(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = int(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Convert booleans to strings using Python's native str type\n",
        "    for col in bool_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = str(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = str(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Combine both metadata dictionaries into one\n",
        "    metadata = {**metadata_prompts, **metadata_response}\n",
        "\n",
        "    records.append(\n",
        "        rg.FeedbackRecord(\n",
        "            fields={\"prompt\": record[\"prompt\"]},\n",
        "            metadata=metadata,\n",
        "            suggestions=[{\"question_name\": \"response\", \"value\": record[\"response\"]}]\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Add records to the dataset and push to Argilla\n",
        "ds.add_records(records)\n",
        "ds.push_to_argilla(name=\"share-gpt-descriptives\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfZAq7sTdJqw"
      },
      "source": [
        "## Questions\n",
        "\n",
        "You can reuse the dataset https://huggingface.co/datasets/argilla/sharegpt-text-descriptives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmeOGb4FdLi2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
