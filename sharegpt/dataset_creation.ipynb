{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiCZcohFc_mu"
      },
      "source": [
        "# Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-cpp-python textdescriptives argilla==1.18 transformers datasets langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
            "Collecting en-core-web-md==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.0/en_core_web_md-3.7.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from en-core-web-md==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (8.2.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.10.13)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (4.66.1)\n",
            "Requirement already satisfied: jinja2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (23.2)\n",
            "Requirement already satisfied: setuptools in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (58.1.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (1.23.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (4.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-md==3.7.0) (2.1.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: --no-binary currently disables reading from the cache of locally built wheels. In the future --no-binary will not influence the wheel cache. pip 23.1 will enforce this behaviour change. A possible replacement is to use the --no-cache-dir option. You can use the flag --use-feature=no-binary-enable-wheel-cache to test the upcoming behaviour. Discussion can be found at https://github.com/pypa/pip/issues/11453\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://dmrepository.datamaran.com:8443/repository/dmPYTHON/simple\n",
            "Requirement already satisfied: ctransformers in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (0.2.27)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from ctransformers) (0.17.3)\n",
            "Requirement already satisfied: fsspec in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
            "Requirement already satisfied: filelock in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (3.13.1)\n",
            "Requirement already satisfied: requests in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (4.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (3.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/davidberenstein/Documents/programming/argilla/awesome-argilla-datasets/.env/lib/python3.9/site-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!CT_METAL=1 pip install -q ctransformers --no-binary ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from ctransformers import AutoModelForCausalLM\n",
        "\n",
        "# # Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
        "# llm = AutoModelForCausalLM.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\", model_file=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\", model_type=\"mistral\")\n",
        "\n",
        "# print(llm(\"AI is going to\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "import textdescriptives as td\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "import spacy\n",
        "from langdetect import detect\n",
        "import argilla as rg\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpkYEwr5dD6w"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "End-to-end workflow to create a dataset in Argilla with text measurements as metadata.\n",
        "This aids in quickly identifying and improving potential dataset issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset creation\n",
        "\n",
        "At first, we need to create a dataset in Argilla. This can either be done by loading a previous created dataset or by creating a new one. In order to avoid duplication, we will check if the dataset already exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RemoteFeedbackDataset(\n",
              "   id=830085b1-274e-4f69-a463-d681faca0377\n",
              "   name=sharegpt\n",
              "   workspace=Workspace(id=e41766d9-89eb-4497-afce-1d96c7ff5f51, name=argilla, inserted_at=2023-10-28 11:26:52.619081, updated_at=2023-10-28 11:26:52.619081)\n",
              "   url=http://localhost:6900/dataset/830085b1-274e-4f69-a463-d681faca0377/annotation-mode\n",
              "   fields=[RemoteTextField(id=UUID('223f85ab-765a-42be-aed7-95bdbf5498e5'), client=None, name='prompt', title='Prompt', required=True, type='text', use_markdown=True), RemoteTextField(id=UUID('fca18ae5-2cd7-4b2b-bffa-27c13bf75e70'), client=None, name='context', title='Context', required=False, type='text', use_markdown=True)]\n",
              "   questions=[RemoteTextQuestion(id=UUID('92f87e74-16b2-42a9-a18c-4ff0b38c9606'), client=None, name='response', title='Response', description=None, required=True, type='text', use_markdown=True), RemoteRatingQuestion(id=UUID('f2c1403a-cb1a-486d-8c56-5dd96f3cda0a'), client=None, name='prompt-quality', title='Prompt Quality', description=None, required=True, type='rating', values=[1, 2, 3, 4, 5, 6, 7]), RemoteLabelQuestion(id=UUID('65176e05-cc79-4288-9465-d5a451edd3e0'), client=None, name='prompt-intent', title='Prompt Intent', description=None, required=True, type='label_selection', labels=['generation', 'rewrite', 'extract', 'closed-qa', 'open-qa', 'classification', 'summarization', 'brainstorming', 'chat', 'code', 'other'], visible_labels=None), RemoteMultiLabelQuestion(id=UUID('eb195fa3-e556-452b-907a-c90fe2d6945e'), client=None, name='prompt-toxicity', title='Prompt Toxicity', description=None, required=False, type='multi_label_selection', labels=['illegal', 'harmfull', 'unqualified advice'], visible_labels=None)]\n",
              "   guidelines=This is a supervised fine-tuning dataset that contains instructions. Please write the response to the instruction in the response field. Take the context into account when writing the response.)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    ds_local = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "    ds_local.questions.extend([\n",
        "        rg.RatingQuestion(\n",
        "            name=\"prompt-quality\", \n",
        "            title=\"Prompt Quality\",\n",
        "            values=list(range(1, 8)), \n",
        "            description=\"How would you rate the quality of the prompt?\",\n",
        "        ),\n",
        "        rg.LabelQuestion(\n",
        "            name=\"prompt-intent\", \n",
        "            title=\"Prompt Intent\",\n",
        "            labels=[\"generation\", \"rewrite\", \"extract\", \"closed-qa\", \"open-qa\", \"classification\", \"summarization\", \"brainstorming\", \"chat\", \"code\", \"other\"], \n",
        "            description=\"What is the intent of the prompt?\"\n",
        "        ),\n",
        "        rg.MultiLabelQuestion(\n",
        "            name=\"prompt-toxicity\", \n",
        "            title=\"Prompt Toxicity\",\n",
        "            labels=[\"illegal\", \"harmfull\", \"unqualified advice\"], \n",
        "            description=\"What are the toxicities in the prompt (if any)?\",\n",
        "            required=False\n",
        "        )\n",
        "    ])\n",
        "    ds_remote = ds_local.push_to_argilla(\"sharegpt\")\n",
        "except Exception as e:\n",
        "    ds_remote = rg.FeedbackDataset.from_argilla(\"sharegpt\")\n",
        "ds_remote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Configure the metadata-properties\n",
        "\n",
        "Next we will be using `text-descriptives` to configure the metadata-properties. This will be used to add and updat relevant metadata-properties to the dataset. Because `text-descriptives` doesn't provide any programmatic interface with the metrics-groups and their sub-metrics, we will run the computation on the an example text and use the results to configure the metadata-properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Both a spacy model and a language were provided. Will use the spacy\n",
            "model and ignore language.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['token_length_mean', 'token_length_median', 'token_length_std',\n",
              "       'sentence_length_mean', 'sentence_length_median', 'sentence_length_std',\n",
              "       'syllables_per_token_mean', 'syllables_per_token_median',\n",
              "       'syllables_per_token_std', 'n_tokens', 'n_unique_tokens',\n",
              "       'proportion_unique_tokens', 'n_characters', 'n_sentences'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric_group = [\"descriptive_stats\"]\n",
        "relevant_subgroups = []\n",
        "df_metrics = td.extract_metrics(\n",
        "    text=[\"this is an example prompt\"], \n",
        "    lang=\"en\", \n",
        "    metrics=metric_group,\n",
        "    spacy_model=\"en_core_web_sm\"\n",
        ").drop(columns=[\"text\"] + relevant_subgroups if relevant_subgroups else [\"text\"])\n",
        "df_metrics.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will be working on converting the `text-descriptives` output to a format that can be used to configure the metadata-properties for our supported types: `TermsMetadataProperty`, `IntegerMetadataProperty` and `FloatMetadataProperty`. Note that we are also applying some subjective formatting choices to ensure that the metadata-properties are easy to read and understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[RemoteFloatMetadataProperty(id=UUID('9691b808-c85e-4248-98bd-89bc2a81b2eb'), client=<httpx.Client object at 0x11105d3d0>, name='response_token_length_mean', title='Response Token Length Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('949d3bf5-a8ec-47c8-a4ce-249a9ee4a922'), client=<httpx.Client object at 0x11105d3d0>, name='response_token_length_median', title='Response Token Length Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('43c7f5a7-e856-4794-9da8-6f89848a3a01'), client=<httpx.Client object at 0x11105d3d0>, name='response_token_length_std', title='Response Token Length Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('4dcca678-229c-43e8-b0d0-9f5fee2ec902'), client=<httpx.Client object at 0x11105d3d0>, name='response_sentence_length_mean', title='Response Sentence Length Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('6938fae3-600d-48f0-afc4-0a37fac5598b'), client=<httpx.Client object at 0x11105d3d0>, name='response_sentence_length_median', title='Response Sentence Length Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('55f449f5-4937-4e7a-8f20-be4fa6937de7'), client=<httpx.Client object at 0x11105d3d0>, name='response_sentence_length_std', title='Response Sentence Length Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('935bf9bc-7da2-40fc-8c50-e1ad47cdbf8f'), client=<httpx.Client object at 0x11105d3d0>, name='response_syllables_per_token_mean', title='Response Syllables Per Token Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('4d4603f4-52e7-4f2c-8856-efb474623653'), client=<httpx.Client object at 0x11105d3d0>, name='response_syllables_per_token_median', title='Response Syllables Per Token Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('32f5cec2-eeed-42fe-bd19-88bf045bb38e'), client=<httpx.Client object at 0x11105d3d0>, name='response_syllables_per_token_std', title='Response Syllables Per Token Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('f722584d-aded-4ca8-9066-98ff2301b405'), client=<httpx.Client object at 0x11105d3d0>, name='response_n_tokens', title='Response N Tokens', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('3c19f5ed-37b7-4b7a-9f9b-ef73a1aebc21'), client=<httpx.Client object at 0x11105d3d0>, name='response_n_unique_tokens', title='Response N Unique Tokens', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('c2f44b5c-65fa-4552-b4e2-317b595f9970'), client=<httpx.Client object at 0x11105d3d0>, name='response_proportion_unique_tokens', title='Response Proportion Unique Tokens', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('7b03c65a-c8b7-4c7f-aebe-bd7176bf3ddf'), client=<httpx.Client object at 0x11105d3d0>, name='response_n_characters', title='Response N Characters', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('1339de81-9e12-4953-966c-5cc77be6e8e3'), client=<httpx.Client object at 0x11105d3d0>, name='response_n_sentences', title='Response N Sentences', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('97d3b9f1-a068-4ed9-81a1-6cd440070b63'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_token_length_mean', title='Prompt Token Length Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('58bd5990-1f69-4ac1-a74b-7e09f515c45d'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_token_length_median', title='Prompt Token Length Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('11935e82-8211-4fbe-832f-f181da2240cc'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_token_length_std', title='Prompt Token Length Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('4d65de9e-2cfb-4591-aca1-8e9fbd5b529f'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_sentence_length_mean', title='Prompt Sentence Length Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('2073cf87-2592-4180-a556-b55cf2703114'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_sentence_length_median', title='Prompt Sentence Length Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('62853ebf-21ce-4855-a772-eeff115f4527'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_sentence_length_std', title='Prompt Sentence Length Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('73c0ef8f-0311-4112-9bb9-90dbc32a45e8'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_syllables_per_token_mean', title='Prompt Syllables Per Token Mean', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('ca7d25af-e12a-48ff-9d65-e8aedfb7a16f'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_syllables_per_token_median', title='Prompt Syllables Per Token Median', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('8465aa0d-5184-4537-ab69-f3204ff14382'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_syllables_per_token_std', title='Prompt Syllables Per Token Std', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('043258b3-8e52-4ef1-95df-9e5564cb65b2'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_n_tokens', title='Prompt N Tokens', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('efacaa54-00f9-4da6-b53f-ad0c406c86e1'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_n_unique_tokens', title='Prompt N Unique Tokens', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('32206dbc-a45c-4aca-861f-d4813675d3bf'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_proportion_unique_tokens', title='Prompt Proportion Unique Tokens', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('469b81a7-75d3-4efd-af48-f0a33b0b8525'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_n_characters', title='Prompt N Characters', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('52e825b0-0ddc-4326-9cc9-cb6f1af6a8e8'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_n_sentences', title='Prompt N Sentences', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('e377ed2e-c5e1-4a74-985d-258c91fc0985'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_entropy', title='Prompt Entropy', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('df8469de-e9e5-405d-8831-b59fcb1c7b9f'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_perplexity', title='Prompt Perplexity', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('2d8e2db1-e2c4-48f8-b7b4-d68301ff1ff8'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_per_word_perplexity', title='Prompt Per Word Perplexity', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('116f3486-f4ed-461d-8f2e-aa8f971d7d44'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_first_order_coherence', title='Prompt First Order Coherence', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('0a44f3ee-6a39-4243-bb0d-c0d48665f061'), client=<httpx.Client object at 0x11105d3d0>, name='prompt_second_order_coherence', title='Prompt Second Order Coherence', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('fb3c0b72-1f85-4c9f-95aa-57ab8def6b74'), client=<httpx.Client object at 0x11105d3d0>, name='response_entropy', title='Response Entropy', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('cb7cc1f5-3a29-4558-ba98-6d76fd2d48bc'), client=<httpx.Client object at 0x11105d3d0>, name='response_perplexity', title='Response Perplexity', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('99e2e5fa-04a3-4f8c-b7a2-727589267b43'), client=<httpx.Client object at 0x11105d3d0>, name='response_per_word_perplexity', title='Response Per Word Perplexity', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('ca169210-9510-4094-87b7-049c10ca22ec'), client=<httpx.Client object at 0x11105d3d0>, name='response_first_order_coherence', title='Response First Order Coherence', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteFloatMetadataProperty(id=UUID('04b9b9bd-1365-4f50-be7e-8bc0b080a7e2'), client=<httpx.Client object at 0x11105d3d0>, name='response_second_order_coherence', title='Response Second Order Coherence', visible_for_annotators=True, type='float', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('62af3f66-7432-4e65-b72c-28288328be69'), client=<httpx.Client object at 0x11105d3d0>, name='prompt__n_sentences', title='Prompt  N Sentences', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('b80ec1af-917e-4652-a4d1-f0c96f4ef6aa'), client=<httpx.Client object at 0x11105d3d0>, name='prompt__n_tokens', title='Prompt  N Tokens', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('0d8a0833-ccf4-4c65-9ba6-77fb753cad77'), client=<httpx.Client object at 0x11105d3d0>, name='response__n_sentences', title='Response  N Sentences', visible_for_annotators=True, type='integer', min=None, max=None),\n",
              " RemoteIntegerMetadataProperty(id=UUID('54ca7491-b9f2-44ce-b000-1b6b08f08a67'), client=<httpx.Client object at 0x11105d3d0>, name='response__n_tokens', title='Response  N Tokens', visible_for_annotators=True, type='integer', min=None, max=None)]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_column_name(col_name):\n",
        "    \"\"\"Clean a column name to fit a specific regex pattern.\"\"\"\n",
        "    col_name = col_name.lower()  # Convert to lowercase\n",
        "    col_name = re.sub(r'[^a-z0-9_]', '_', col_name)  # Replace non-alphanumeric characters with underscores\n",
        "    return col_name\n",
        "\n",
        "def create_metadata_properties(df, prefix):\n",
        "    \"\"\"Generate metadata properties based on dataframe columns and data types.\"\"\"\n",
        "    properties = []\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        name = f\"{prefix}_{clean_column_name(col)}\"\n",
        "        title = name.replace('_', ' ').title()\n",
        "\n",
        "        if dtype == 'object':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'int64':\n",
        "            prop = rg.IntegerMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'float64':\n",
        "            prop = rg.FloatMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'bool':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        else:\n",
        "            print(f\"Unhandled data type for column {col}: {dtype}\")\n",
        "            continue\n",
        "        properties.append(prop)\n",
        "    return properties\n",
        "\n",
        "metadata_properties = []\n",
        "metadata_properties += create_metadata_properties(df_metrics, 'prompt')\n",
        "metadata_properties += create_metadata_properties(df_metrics, 'response')\n",
        "for metadata_property in metadata_properties:\n",
        "    try:\n",
        "        field = ds_remote.metadata_property_by_name(metadata_property.name)\n",
        "        if not field:\n",
        "            ds_remote.add_metadata_property(metadata_property)\n",
        "    except (KeyError, ValueError) as e:\n",
        "        ds_remote.add_metadata_property(metadata_property)        \n",
        "ds_remote.metadata_properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['n_sentences', 'n_characters', 'n_unique_tokens', 'n_tokens'], [])"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"totally-not-an-llm/sharegpt-hyperfiltered-3k\", split=\"train[:10]\")\n",
        "dataset = dataset.filter(lambda x: x[\"conversations\"][0][\"from\"] == \"human\")\n",
        "dataset = dataset.map(lambda x: {\"prompt\": x[\"conversations\"][0][\"value\"], \"response\": x[\"conversations\"][1][\"value\"]})\n",
        "\n",
        "# Extract metrics\n",
        "spacy_model = \"en_core_web_md\" # we need a model with vectors\n",
        "df_prompt = td.extract_metrics(text=dataset[\"prompt\"], metrics=metric_group, spacy_model=spacy_model).drop(columns=['text'])\n",
        "df_response = td.extract_metrics(text=dataset[\"response\"], metrics=metric_group, spacy_model=spacy_model).drop(columns=['text'])\n",
        "\n",
        "# Identify integer and boolean columns for prompts and responses\n",
        "int_cols_prompts = df_prompt.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_prompts = df_prompt.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "int_cols_responses = df_response.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_responses = df_response.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "# Combine column lists for prompts and responses\n",
        "int_cols = list(set(int_cols_prompts + int_cols_responses))\n",
        "bool_cols = list(set(bool_cols_prompts + bool_cols_responses))\n",
        "int_cols, bool_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will be casting the `numpy`-datatypes to basic Python built-in datatypes. This is required because the Argilla client doesn't support `numpy`-datatypes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Functions ---\n",
        "def cast_to_python_types(df):\n",
        "    \"\"\"\n",
        "    Convert integer and boolean columns to Python native types.\n",
        "    \"\"\"\n",
        "    for column in df.columns:\n",
        "        df[column].fillna(0, inplace=True)\n",
        "        if df[column].dtype == bool:\n",
        "            df[column] = df[column].astype(str)\n",
        "        elif df[column].dtype == np.int64:\n",
        "            df[column] = df[column].astype(int)\n",
        "        elif df[column].dtype == np.float64:\n",
        "            df[column] = df[column].astype(float)\n",
        "        else:\n",
        "            print(f\"Unhandled data type for column {column}: {df[column].dtype}\")\n",
        "    return df\n",
        "\n",
        "df_prompt = cast_to_python_types(df_prompt)\n",
        "df_response = cast_to_python_types(df_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we will loop through the Hugging Face dataset, add the metadata-properties and update the Argilla dataset with the new records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "Zt9XZrLtc2Km"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pushing records to Argilla...: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s]\n"
          ]
        }
      ],
      "source": [
        "# Prepare feedback records with metadata and suggestions\n",
        "records = []\n",
        "\n",
        "cols_with_values_other_than_zeros_or_nan_prompt = df_prompt.columns[~(df_prompt.fillna(0) == 0).all() & ~df_prompt.isnull().any()].tolist()\n",
        "cols_with_values_other_than_zeros_or_nan_response = df_response.columns[~(df_response.fillna(0) == 0).all() & ~df_response.isnull().any()].tolist()\n",
        "\n",
        "\n",
        "for i, record in enumerate(dataset):\n",
        "    # Prepare metadata for prompts\n",
        "    metadata_prompts = {f\"prompt_{col}\": value for col, value in df_prompt[cols_with_values_other_than_zeros_or_nan_prompt].iloc[i].items()}\n",
        "    # Prepare metadata for responses\n",
        "    metadata_response = {f\"response_{col}\": value for col, value in df_response[cols_with_values_other_than_zeros_or_nan_response].iloc[i].items()}\n",
        "\n",
        "    # Explicitly cast integers using Python's native int type\n",
        "    for col in int_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = int(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = int(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Convert booleans to strings using Python's native str type\n",
        "    for col in bool_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = str(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = str(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Combine both metadata dictionaries into one\n",
        "    metadata = {**metadata_prompts, **metadata_response}\n",
        "    record = rg.FeedbackRecord(\n",
        "        fields={\"prompt\": record[\"prompt\"]},\n",
        "        metadata=metadata,\n",
        "        suggestions=[{\"question_name\": \"response\", \"value\": record[\"response\"]}]\n",
        "    )\n",
        "    records.append(record)\n",
        "\n",
        "# Add records to the dataset and push to Argilla\n",
        "ds_remote.add_records(records)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
