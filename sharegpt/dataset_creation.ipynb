{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset creation"
      ],
      "metadata": {
        "id": "AiCZcohFc_mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "RpkYEwr5dD6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt9XZrLtc2Km"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "End-to-end workflow to create a dataset in Argilla with text measurements as metadata.\n",
        "This aids in quickly identifying and improving potential dataset issues.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import textdescriptives as td\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "# --- Functions ---\n",
        "def clean_column_name(col_name):\n",
        "    \"\"\"Clean a column name to fit a specific regex pattern.\"\"\"\n",
        "    col_name = col_name.lower()  # Convert to lowercase\n",
        "    col_name = re.sub(r'[^a-z0-9_]', '_', col_name)  # Replace non-alphanumeric characters with underscores\n",
        "    return col_name\n",
        "\n",
        "def create_metadata_properties(df, prefix):\n",
        "    \"\"\"Generate metadata properties based on dataframe columns and data types.\"\"\"\n",
        "    properties = []\n",
        "    for col, dtype in df.dtypes.items():\n",
        "        name = f\"{prefix}_{clean_column_name(col)}\"\n",
        "        title = name.replace('_', ' ').title()\n",
        "\n",
        "        if dtype == 'object':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'int64':\n",
        "            prop = rg.IntegerMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'float64':\n",
        "            prop = rg.FloatMetadataProperty(name=name, title=title)\n",
        "        elif dtype == 'bool':\n",
        "            prop = rg.TermsMetadataProperty(name=name, title=title)\n",
        "        else:\n",
        "            print(f\"Unhandled data type for column {col}: {dtype}\")\n",
        "            continue\n",
        "        properties.append(prop)\n",
        "    return properties\n",
        "\n",
        "def cast_to_python_types(df):\n",
        "    \"\"\"\n",
        "    Convert integer and boolean columns to Python native types.\n",
        "    \"\"\"\n",
        "    int_cols = df.select_dtypes(include=['int64']).columns\n",
        "    bool_cols = df.select_dtypes(include=['boolean']).columns\n",
        "\n",
        "    # Explicitly cast integers using Python's native int type\n",
        "    for col in int_cols:\n",
        "        df[col] = df[col].apply(int)\n",
        "\n",
        "    # Convert booleans to strings using Python's native str type\n",
        "    for col in bool_cols:\n",
        "        df[col] = df[col].apply(str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def detect_language(text):\n",
        "    \"\"\"\n",
        "    Detect the language of a given text.\n",
        "\n",
        "    Args:\n",
        "    - text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "    - str: Detected language (ISO 639-1 code).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"unknown\"  # In case the language detection fails\n",
        "\n",
        "\n",
        "\n",
        "# --- Data Collection ---\n",
        "dataset = load_dataset(\"totally-not-an-llm/sharegpt-hyperfiltered-3k\", split=\"train\")\n",
        "dataset = dataset.filter(lambda x: x[\"conversations\"][0][\"from\"] == \"human\")\n",
        "dataset = dataset.map(lambda x: {\"prompt\": x[\"conversations\"][0][\"value\"], \"response\": x[\"conversations\"][1][\"value\"]})\n",
        "\n",
        "# Extract metrics\n",
        "df_prompt = td.extract_metrics(text=dataset[\"prompt\"], lang=\"en\").drop(columns=['text'])\n",
        "df_response = td.extract_metrics(text=dataset[\"response\"], lang=\"en\").drop(columns=['text'])\n",
        "\n",
        "# Identify integer and boolean columns for prompts and responses\n",
        "int_cols_prompts = df.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_prompts = df.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "int_cols_responses = df_response.select_dtypes(include=['int64']).columns.tolist()\n",
        "bool_cols_responses = df_response.select_dtypes(include=['boolean']).columns.tolist()\n",
        "\n",
        "# Combine column lists for prompts and responses\n",
        "int_cols = list(set(int_cols_prompts + int_cols_responses))\n",
        "bool_cols = list(set(bool_cols_prompts + bool_cols_responses))\n",
        "\n",
        "# --- Metadata Preparation ---\n",
        "metadata_prompt = create_metadata_properties(df_prompt, 'prompt')\n",
        "metadata_response = create_metadata_properties(df_response, 'response')\n",
        "\n",
        "all_metadata = metadata_prompt + metadata_response\n",
        "\n",
        "ds = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "for m in all_metadata:\n",
        "    ds.add_metadata_property(m)\n",
        "\n",
        "# --- Record Preparation ---\n",
        "records = []\n",
        "\n",
        "# Prepare feedback records with metadata and suggestions\n",
        "\n",
        "# Identify columns with values other than zeros or NaN for both prompt and response\n",
        "cols_with_values_other_than_zeros_or_nan_prompt = df_prompt.columns[~(df_prompt.fillna(0) == 0).all()].tolist()\n",
        "cols_with_values_other_than_zeros_or_nan_response = df_response.columns[~(df_response.fillna(0) == 0).all()].tolist()\n",
        "\n",
        "\n",
        "records = []\n",
        "\n",
        "cols_with_values_other_than_zeros_or_nan_prompt = df_prompt.columns[~(df_prompt.fillna(0) == 0).all() & ~df_prompt.isnull().any()].tolist()\n",
        "cols_with_values_other_than_zeros_or_nan_response = df_response.columns[~(df_response.fillna(0) == 0).all() & ~df_response.isnull().any()].tolist()\n",
        "\n",
        "ds = rg.FeedbackDataset.for_supervised_fine_tuning(context=True, use_markdown=True, guidelines=None)\n",
        "for m in all_metadata:\n",
        "    ds.add_metadata_property(m)\n",
        "\n",
        "for i, record in enumerate(dataset):\n",
        "    # Prepare metadata for prompts\n",
        "    metadata_prompts = {f\"prompt_{col}\": value for col, value in df_prompt[cols_with_values_other_than_zeros_or_nan_prompt].iloc[i].items()}\n",
        "    # Prepare metadata for responses\n",
        "    metadata_response = {f\"response_{col}\": value for col, value in df_response[cols_with_values_other_than_zeros_or_nan_response].iloc[i].items()}\n",
        "    if \"prompt_smog\" in metadata_prompts.keys():\n",
        "      print(metadata_prompts)\n",
        "\n",
        "    # Explicitly cast integers using Python's native int type\n",
        "    for col in int_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = int(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = int(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Convert booleans to strings using Python's native str type\n",
        "    for col in bool_cols:\n",
        "        if f\"prompt_{col}\" in metadata_prompts:\n",
        "            metadata_prompts[f\"prompt_{col}\"] = str(metadata_prompts[f\"prompt_{col}\"])\n",
        "        if f\"response_{col}\" in metadata_response:\n",
        "            metadata_response[f\"response_{col}\"] = str(metadata_response[f\"response_{col}\"])\n",
        "\n",
        "    # Combine both metadata dictionaries into one\n",
        "    metadata = {**metadata_prompts, **metadata_response}\n",
        "\n",
        "    records.append(\n",
        "        rg.FeedbackRecord(\n",
        "            fields={\"prompt\": record[\"prompt\"]},\n",
        "            metadata=metadata,\n",
        "            suggestions=[{\"question_name\": \"response\", \"value\": record[\"response\"]}]\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Add records to the dataset and push to Argilla\n",
        "ds.add_records(records)\n",
        "ds.push_to_argilla(name=\"share-gpt-descriptives\", workspace=\"admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "You can reuse the dataset https://huggingface.co/datasets/argilla/sharegpt-text-descriptives"
      ],
      "metadata": {
        "id": "lfZAq7sTdJqw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmeOGb4FdLi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}